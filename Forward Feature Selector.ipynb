{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_feature_selector(model, x_train, y_train, n_features = None, cv = 5, metric = 'roc_auc', verbose = True):\n",
    "    \n",
    "    '''\n",
    "    Feedforward Feature Selection \n",
    "        Input:\n",
    "            model: \n",
    "                The base estimator to build models on.\n",
    "            x_train: \n",
    "                Training data without target\n",
    "            y_train:\n",
    "                Training Target labels\n",
    "            n_features: Default = None\n",
    "                Max features to extract\n",
    "            cv: Default = 5\n",
    "                Number of cross validations to do for CV-Score Calculation\n",
    "            metric: str, Default = 'roc_auc'\n",
    "                Metric to be evaluated on. Available metrics supported with sklearn cross_val_score\n",
    "            verbose: bool, Default = True\n",
    "                Whether to keep verbosity or not\n",
    "          \n",
    "        Returns: \n",
    "            list of most useful features\n",
    "    \n",
    "    Prerequisites:\n",
    "    \n",
    "    >>> import numpy as np\n",
    "    >>> import multiprocessing\n",
    "    >>> from joblib import Parallel, delayed\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    '''\n",
    "      \n",
    "    useful_columns = []\n",
    "    columns_indices = list(range(x_train.shape[1]))\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    \n",
    "    selecting = True\n",
    "    i = 1\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Starting Forward Feature Selection...\")\n",
    "        print(\"Number of tasks = {}\".format(x_train.shape[1]))\n",
    "        \n",
    "    cv_scores = []\n",
    "    \n",
    "    while selecting == True:\n",
    "        \n",
    "        \n",
    "        if verbose:\n",
    "            start = datetime.now()\n",
    "            print(f'{start}: Features: {i}/{x_train.shape[1]}: ', end = '')\n",
    "\n",
    "\n",
    "        def model_feat(column_index, useful_columns):   \n",
    "            \n",
    "            #list of all the columns to model on\n",
    "            columns_to_model_on = useful_columns\n",
    "            columns_to_model_on.append(column_index)\n",
    "\n",
    "            \n",
    "            cv_score_column = cross_val_score(model, x_train[:,columns_to_model_on], y_train, cv = cv, scoring = metric)\n",
    "            \n",
    "            return (column_index, cv_score_column.mean())\n",
    "        \n",
    "        #parallely building the model for feature selection\n",
    "        cv_scores_bank = Parallel(n_jobs = num_cores)(delayed(model_feat)(col, useful_columns) for col in columns_indices)\n",
    "            \n",
    "        cv_scores_bank = dict(cv_scores_bank)\n",
    "        #fetching index of best column\n",
    "        highest_cv_column = list(cv_scores_bank.keys())[np.argmax(list(cv_scores_bank.values()))]\n",
    "        \n",
    "        #adding the index of useful column to set\n",
    "        useful_columns.append(highest_cv_column)\n",
    "        #removing the index of column from column_indices\n",
    "        columns_indices.remove(highest_cv_column)\n",
    "        \n",
    "        best_cv_score = cv_scores_bank[highest_cv_column]\n",
    "        cv_scores.append(best_cv_score)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f' CV_Score = {best_cv_score}')\n",
    "            print(f\"Time Elapsed = {datetime.now() - start}\\n\")\n",
    "        \n",
    "        if n_features:\n",
    "            if i == n_features:\n",
    "                if verbose:\n",
    "                    print(\"No further improvement in CV score\")\n",
    "                    print(\"Stopping further Selection\")\n",
    "                selecting = False \n",
    "                \n",
    "        if i>1:\n",
    "            if cv_scores[i-1] <= cv_scores[i-2]:\n",
    "                \n",
    "                if verbose:\n",
    "                    print(\"No further improvement in CV score\")\n",
    "                    print(\"Stopping further Selection\")\n",
    "                selecting = False\n",
    "        i += 1\n",
    "                \n",
    "    return useful_columns\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
